---
# Production-Ready Alertmanager Configuration
# Includes routing, grouping, inhibition, and multiple notification channels

global:
  # Global configuration
  resolve_timeout: 5m

  # PagerDuty
  pagerduty_url: 'https://events.pagerduty.com/v2/enqueue'

  # Slack
  slack_api_url: 'https://hooks.slack.com/services/YOUR/WEBHOOK/URL'

  # SMTP
  smtp_from: 'alertmanager@example.com'
  smtp_smarthost: 'smtp.gmail.com:587'
  smtp_auth_username: 'alertmanager@example.com'
  smtp_auth_password: '${SMTP_PASSWORD}'  # Set via environment variable
  smtp_require_tls: true

# Templates for notification formatting
templates:
  - '/etc/alertmanager/templates/*.tmpl'

# Routing tree - determines where alerts go
route:
  # Default receiver if no routes match
  receiver: 'default'

  # Group alerts by these labels
  group_by: ['alertname', 'cluster', 'service']

  # Wait 30s before sending first notification (allows grouping)
  group_wait: 30s

  # Wait 5m before sending notifications about new alerts in existing group
  group_interval: 5m

  # Repeat notifications every 4 hours if alert still firing
  repeat_interval: 4h

  # Child routes (evaluated top to bottom)
  routes:
    # === Critical Production Alerts → PagerDuty + Slack ===
    - match:
        severity: critical
        environment: production
      receiver: 'pagerduty-critical'
      group_wait: 10s
      repeat_interval: 1h
      continue: true  # Also send to next matching route

    - match:
        severity: critical
        environment: production
      receiver: 'slack-incidents'
      group_wait: 10s

    # === Warning Production Alerts → Slack Only ===
    - match:
        severity: warning
        environment: production
      receiver: 'slack-warnings'
      group_wait: 1m
      repeat_interval: 12h

    # === Team-Specific Routing ===

    # Database team
    - match:
        team: database
      receiver: 'database-team'
      group_by: ['alertname', 'instance']
      group_wait: 30s
      repeat_interval: 6h
      routes:
        # Critical DB issues → Page + Email
        - match:
            severity: critical
          receiver: 'database-pagerduty'
          continue: true
        - match:
            severity: critical
          receiver: 'database-team'

    # Frontend team
    - match:
        team: frontend
      receiver: 'frontend-slack'
      group_wait: 2m
      repeat_interval: 8h

    # Platform team
    - match:
        team: platform
      receiver: 'platform-slack'
      group_wait: 1m

    # === Environment-Based Routing ===

    # Staging environment → Low priority
    - match:
        environment: staging
      receiver: 'slack-staging'
      group_wait: 5m
      repeat_interval: 24h

    # Development environment → Even lower priority
    - match:
        environment: dev
      receiver: 'slack-dev'
      group_wait: 10m
      repeat_interval: 48h

    # === Business Hours vs After Hours ===

    # Critical alerts outside business hours → Escalate faster
    - match:
        severity: critical
      mute_time_intervals:
        - business_hours
      receiver: 'pagerduty-critical'
      repeat_interval: 30m  # More frequent pages after hours

    # Warnings only during business hours
    - match:
        severity: warning
      active_time_intervals:
        - business_hours
      receiver: 'slack-warnings'

    # === SLO Alerts → Dedicated Channel ===
    - match_re:
        slo: '.+'
      receiver: 'slack-slo'
      group_by: ['slo', 'service']
      group_wait: 2m

    # === Certificate Alerts → Security Team ===
    - match_re:
        alertname: 'Certificate.*'
      receiver: 'security-team'

    # === Test Alerts → Null (discard) ===
    - match:
        test: 'true'
      receiver: 'null'

# Time intervals for conditional routing
time_intervals:
  # Business hours: Mon-Fri 9am-5pm EST
  - name: business_hours
    time_intervals:
      - weekdays: ['monday:friday']
        times:
          - start_time: '09:00'
            end_time: '17:00'
        location: 'America/New_York'

  # Weekend
  - name: weekend
    time_intervals:
      - weekdays: ['saturday', 'sunday']

  # Maintenance window: Sunday 2-4am EST
  - name: maintenance_window
    time_intervals:
      - weekdays: ['sunday']
        times:
          - start_time: '02:00'
            end_time: '04:00'
        location: 'America/New_York'

# Inhibition rules - suppress alerts based on other alerts
inhibit_rules:
  # If critical alert is firing, suppress warnings for same alert
  - source_match:
      severity: critical
    target_match:
      severity: warning
    equal: ['alertname', 'service', 'instance']

  # If node is down, suppress all resource alerts from that node
  - source_match:
      alertname: NodeDown
    target_match_re:
      alertname: '(HighCPU|HighMemory|DiskSpace.*|HighLoad.*)'
    equal: ['instance']

  # If service is down, suppress error rate and latency alerts
  - source_match:
      alertname: ServiceDown
    target_match_re:
      alertname: '(HighErrorRate|HighLatency|HealthCheckFailing)'
    equal: ['service']

  # If datacenter is down, suppress everything from that datacenter
  - source_match:
      alertname: DatacenterDown
    target_match_re:
      alertname: '.*'
    equal: ['datacenter']

  # If database is down, suppress connection and replication alerts
  - source_match:
      alertname: DatabaseDown
    target_match_re:
      alertname: 'Database.*'
    equal: ['instance']

  # If error budget burn is critical, suppress latency warnings
  - source_match:
      alertname: ErrorBudgetBurnRateFast
    target_match:
      alertname: LatencySLOBreach
    equal: ['service']

# Receivers - notification destinations
receivers:
  # === Default Receiver ===
  - name: 'default'
    slack_configs:
      - channel: '#alerts'
        username: 'Alertmanager'
        icon_emoji: ':fire:'
        title: '[{{ .Status | toUpper }}] {{ .GroupLabels.alertname }}'
        text: |
          {{ range .Alerts }}
          *Summary*: {{ .Annotations.summary }}
          *Description*: {{ .Annotations.description }}
          *Severity*: {{ .Labels.severity }}
          *Service*: {{ .Labels.service }}
          {{ if .Annotations.runbook_url }}*Runbook*: {{ .Annotations.runbook_url }}{{ end }}
          {{ end }}
        color: '{{ if eq .Status "firing" }}danger{{ else }}good{{ end }}'
        send_resolved: true

  # === PagerDuty - Critical Alerts ===
  - name: 'pagerduty-critical'
    pagerduty_configs:
      - service_key: '${PAGERDUTY_SERVICE_KEY}'
        url: 'https://events.pagerduty.com/v2/enqueue'
        severity: 'critical'
        description: '{{ .GroupLabels.alertname }}: {{ .CommonAnnotations.summary }}'
        details:
          firing: '{{ .Alerts.Firing | len }}'
          resolved: '{{ .Alerts.Resolved | len }}'
          instances: '{{ range .Alerts }}{{ .Labels.instance }} {{ end }}'
          impact: '{{ .CommonAnnotations.impact }}'
          runbook: '{{ .CommonAnnotations.runbook_url }}'
        client: 'Alertmanager'
        client_url: 'https://alertmanager.example.com'
        send_resolved: true

  # === Slack - Incidents Channel (Critical) ===
  - name: 'slack-incidents'
    slack_configs:
      - channel: '#incidents'
        username: 'Alertmanager'
        icon_emoji: ':rotating_light:'
        title: 'CRITICAL: {{ .GroupLabels.alertname }}'
        title_link: '{{ .CommonAnnotations.dashboard_url }}'
        text: |
          *Impact*: {{ .CommonAnnotations.impact }}

          {{ range .Alerts }}
          • *{{ .Labels.instance }}*: {{ .Annotations.description }}
          {{ end }}

          {{ if .CommonAnnotations.runbook_url }}:book: <{{ .CommonAnnotations.runbook_url }}|Runbook>{{ end }}
          {{ if .CommonAnnotations.dashboard_url }}:chart_with_upwards_trend: <{{ .CommonAnnotations.dashboard_url }}|Dashboard>{{ end }}
        color: 'danger'
        send_resolved: true
        actions:
          - type: button
            text: 'View Runbook :book:'
            url: '{{ .CommonAnnotations.runbook_url }}'
          - type: button
            text: 'Acknowledge in PagerDuty'
            url: 'https://example.pagerduty.com'
          - type: button
            text: 'Silence :no_bell:'
            url: 'https://alertmanager.example.com/#/silences/new'

  # === Slack - Warnings Channel ===
  - name: 'slack-warnings'
    slack_configs:
      - channel: '#monitoring'
        username: 'Alertmanager'
        icon_emoji: ':warning:'
        title: 'Warning: {{ .GroupLabels.alertname }}'
        text: '{{ range .Alerts }}{{ .Annotations.summary }}\n{{ end }}'
        color: 'warning'
        send_resolved: true

  # === Slack - SLO Alerts ===
  - name: 'slack-slo'
    slack_configs:
      - channel: '#slo-alerts'
        username: 'SLO Monitor'
        icon_emoji: ':chart_with_downwards_trend:'
        title: 'SLO Alert: {{ .GroupLabels.slo }} - {{ .GroupLabels.service }}'
        text: |
          {{ range .Alerts }}
          {{ .Annotations.description }}
          {{ if .Annotations.runbook_url }}Runbook: {{ .Annotations.runbook_url }}{{ end }}
          {{ end }}
        color: '{{ if eq .Status "firing" }}warning{{ else }}good{{ end }}'

  # === Slack - Staging Environment ===
  - name: 'slack-staging'
    slack_configs:
      - channel: '#staging-alerts'
        username: 'Alertmanager [Staging]'
        title: '[STAGING] {{ .GroupLabels.alertname }}'
        text: '{{ range .Alerts }}{{ .Annotations.summary }}{{ end }}'

  # === Slack - Dev Environment ===
  - name: 'slack-dev'
    slack_configs:
      - channel: '#dev-alerts'
        username: 'Alertmanager [Dev]'
        title: '[DEV] {{ .GroupLabels.alertname }}'
        text: '{{ range .Alerts }}{{ .Annotations.summary }}{{ end }}'

  # === Team-Specific Receivers ===

  # Database team
  - name: 'database-team'
    email_configs:
      - to: 'db-team@example.com'
        from: 'alertmanager@example.com'
        headers:
          Subject: '[DB Alert] {{ .GroupLabels.alertname }}'
        html: '{{ template "email.html" . }}'
        text: '{{ template "email.text" . }}'
        send_resolved: true

  - name: 'database-pagerduty'
    pagerduty_configs:
      - service_key: '${PAGERDUTY_DB_KEY}'
        description: 'Database: {{ .GroupLabels.alertname }}'

  # Frontend team
  - name: 'frontend-slack'
    slack_configs:
      - channel: '#frontend-alerts'
        username: 'Frontend Monitor'
        title: '{{ .GroupLabels.alertname }}'
        text: '{{ range .Alerts }}{{ .Annotations.summary }}{{ end }}'

  # Platform team
  - name: 'platform-slack'
    slack_configs:
      - channel: '#platform-alerts'
        username: 'Platform Monitor'
        title: '{{ .GroupLabels.alertname }}'
        text: '{{ range .Alerts }}{{ .Annotations.summary }}{{ end }}'

  # Security team
  - name: 'security-team'
    email_configs:
      - to: 'security@example.com'
        headers:
          Subject: '[Security Alert] {{ .GroupLabels.alertname }}'
    slack_configs:
      - channel: '#security-alerts'
        title: ':lock: {{ .GroupLabels.alertname }}'

  # === Webhook Receiver ===
  - name: 'webhook'
    webhook_configs:
      - url: 'https://api.example.com/alerts'
        send_resolved: true
        http_config:
          bearer_token: '${WEBHOOK_TOKEN}'
        max_alerts: 0  # Send all alerts, no limit

  # === Null Receiver (discard) ===
  - name: 'null'
